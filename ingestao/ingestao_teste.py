import json
import feedparser
import google.generativeai as genai
import psycopg2
import time
import re   # Fun√ß√£o para limpeza de JSON
from datetime import datetime


# CONFIGURA√á√ÉO
DB_CONFIG = "dbname=vigimanaus user=postgres password=postgres host=localhost port=5433"
GEMINI_KEY = "" # Pegue a chave no Google AI Studio e jogue dentro das aspas
genai.configure(api_key=GEMINI_KEY)

# Conex√£o com Banco
conn = psycopg2.connect(DB_CONFIG)
cur = conn.cursor()

# ==========================================================
# FUN√á√ÉO AUXILIAR: LIMPEZA DE JSON
# ==========================================================
def limpar_json(texto):
    """
    Remove marcadores de c√≥digo (```json) e tenta encontrar
    o JSON v√°lido dentro da resposta da IA.
    """
    # Remove blocos de c√≥digo markdown
    texto = texto.replace('```json', '').replace('```', '')
    
    # Tenta encontrar o conte√∫do entre a primeira { e a √∫ltima }
    # Isso ajuda caso a IA escreva texto antes ou depois do JSON
    match = re.search(r'\{.*\}', texto, re.DOTALL)
    if match:
        return match.group(0)
    return texto

# ==========================================================
# 1. PROCESSAR GUARDI√ïES DA SA√öDE (JSON LOCAL)
# ==========================================================
def processar_gds():
    print("--- Processando Guardi√µes da Sa√∫de ---")
    try:
        with open('gds-json-exemplos.json', 'r', encoding='utf-8') as f:
            dados = json.load(f)
    except FileNotFoundError:
        print("Arquivo 'gds-json-exemplos.json' n√£o encontrado. Pulando etapa.")
        return

    for registro in dados:
        time.sleep(10) # Para evitar rate limit da API
        try:
            answers = {item['field']: item['value'] for item in registro['answers']}
            
            titulo = answers.get('evento_descricao', 'Relato GdS')
            descricao = answers.get('evento_detalhes', '')
            local = answers.get('evento_local_ocorrencia', '')
            data_str = answers.get('evento_data_ocorrencia', '')
            
            # O GdS j√° vem estruturado, mas utiliza-se o Gemini para 
            # estimar o N√≠vel de Risco e validar relev√¢ncia
            prompt = f"""
            Analise este relato de sa√∫de participativa:
            T√≠tulo: {titulo}
            Detalhes: {descricao}
            Local: {local}
            
            Responda APENAS um JSON:
            {{
                "nivel_risco": "Alto, M√©dio ou Baixo",
                "bairro_estimado": "Nome do bairro em Manaus (se n√£o for Manaus, coloque 'Externo')",
                "latitude": "float (estime a lat de Manaus)",
                "longitude": "float (estime a long de Manaus)"
            }}
            """
            
            model = genai.GenerativeModel('gemini-2.5-flash-lite')
            response = model.generate_content(prompt)
            
            # Limpeza
            texto_limpo = limpar_json(response.text)
            ai_data = json.loads(texto_limpo)
            
            # Ajuste para limites do banco
            bairro_tratado = ai_data.get('bairro_estimado', 'Desconhecido')[:499] 
            
            sql = """
                INSERT INTO sinais_dois (titulo, descricao, status, nivel_risco, localizacao_bairro, geom, fonte_id)
                VALUES (%s, %s, 'Pendente', %s, %s, ST_SetSRID(ST_MakePoint(%s, %s), 4326), 3)
            """
            cur.execute(sql, (
                titulo, 
                descricao, 
                ai_data.get('nivel_risco', 'Baixo'),
                bairro_tratado,
                ai_data.get('longitude', -60.0217), # Fallback para Manaus
                ai_data.get('latitude', -3.1190) # Fallback para Manaus
            ))
            conn.commit()
            print(f"‚úÖ GdS Importado: {titulo}")
            
        except Exception as e:
            conn.rollback() 
            print(f"‚ùå Erro GdS: {e}")

# ==========================================================
# 2. PROCESSAR EIOS (RSS ONLINE)
# ==========================================================
def processar_eios():
    print("\n--- Processando Feed EIOS ---")
    url = "https://portal.who.int/eios/API/News/Monitoring/getBoardRssFeed?queryId=1693"
    
    print(f"üì° Conectando a: {url} ...")
    
    try:
        feed = feedparser.parse(url)
        
        # === DIAGN√ìSTICO DE CONEX√ÉO ===
        status = getattr(feed, 'status', 'N/A')
        total_entries = len(feed.entries)
        print(f"üì° Status HTTP: {status}")
        print(f"üìÑ Not√≠cias encontradas: {total_entries}")
        
        if total_entries == 0:
            print("‚ö†Ô∏è Nenhuma not√≠cia encontrada. O feed pode estar vazio ou inacess√≠vel.")
            if hasattr(feed, 'bozo_exception'):
                print(f"üîç Erro interno do parser: {feed.bozo_exception}")
            return

    except Exception as e:
        print(f"‚ùå Erro Cr√≠tico ao baixar feed: {e}")
        return

    for entry in feed.entries:
        time.sleep(10) # Para evitar rate limit da API
        try:
            titulo = entry.title
            resumo = entry.description
            link = entry.link
            
            # FILTRAGEM COM IA - O feed tem not√≠cias do mundo todo. Filtra s√≥ o que parece ser amea√ßa.
            prompt = f"""
            Analise esta not√≠cia de sa√∫de p√∫blica global:
            T√≠tulo: {titulo}
            Resumo: {resumo}
            
            1. √â uma doen√ßa infecciosa ou surto?
            2. √â relevante para o Brasil/Amazonas? (Sim/N√£o)
            3. Qual o n√≠vel de risco?
            
            Responda estritamente neste formato JSON:
            {{
                "relevante": true/false,
                "doenca": "Nome da doen√ßa",
                "local": "Cidade/Pa√≠s mencionado",
                "nivel_risco": "Alto/M√©dio/Baixo"
            }}
            """
            
            model = genai.GenerativeModel('gemini-2.5-flash-lite')
            response = model.generate_content(prompt)
            
            # Limpeza
            texto_limpo = limpar_json(response.text)
            ai_data = json.loads(texto_limpo)
            
            # S√≥ salva se a IA achar relevante OU caso queira demonstrar a ingest√£o global
            # Para o prot√≥tipo, salva tudo, colocando 'Descartado' se n√£o for relevante
            status = 'Pendente' if ai_data.get('relevante') else 'Descartado'
            
            titulo_completo = f"[{ai_data.get('doenca', 'Geral')}] {titulo}"
            
            local_db = ai_data.get('local', 'Global')[:499]
            
            descricao_db = f"{resumo} (Fonte Original: {link})"
            
            sql = """
                INSERT INTO sinais_dois (titulo, descricao, status, nivel_risco, localizacao_bairro, geom, fonte_id)
                VALUES (%s, %s, %s, %s, %s, ST_SetSRID(ST_MakePoint(-60.02, -3.10), 4326), 1)
            """
            
            # Nota: Fixado a coordenada de Manaus para o EIOS pois as noticias s√£o globais,
            # mas meu TCC monitora riscos para Manaus.

            cur.execute(sql, (
                titulo_completo, 
                descricao_db, 
                status,
                ai_data.get('nivel_risco', 'Baixo'),
                local_db
            ))
            conn.commit()
            print(f"‚úÖ EIOS Processado: {titulo_completo[:50]}... -> Relevante? {ai_data.get('relevante')}")
            
        except Exception as e:
            conn.rollback() 
            print(f"‚ùå Erro EIOS no item '{titulo[:20]}...': {e}")

# Executar
if __name__ == "__main__":
    processar_gds()
    processar_eios()
    cur.close()
    conn.close()